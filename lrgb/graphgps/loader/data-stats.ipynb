{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "73b862f3-3d84-4e4b-bd0c-137d90ebabf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.voc_superpixels import VOCSuperpixels\n",
    "from dataset.coco_superpixels import COCOSuperpixels\n",
    "from dataset.peptides_functional import PeptidesFunctionalDataset\n",
    "from split_generator import *\n",
    "\n",
    "\n",
    "import torch_geometric\n",
    "import torch\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3566c2e4-a213-4223-a336-04a71b41ee5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_dataset_splits(datasets):\n",
    "    \"\"\"Join train, val, test datasets into one dataset object.\n",
    "\n",
    "    Args:\n",
    "        datasets: list of 3 PyG datasets to merge\n",
    "\n",
    "    Returns:\n",
    "        joint dataset with `split_idxs` property storing the split indices\n",
    "    \"\"\"\n",
    "    assert len(datasets) == 3, \"Expecting train, val, test datasets\"\n",
    "\n",
    "    n1, n2, n3 = len(datasets[0]), len(datasets[1]), len(datasets[2])\n",
    "    data_list = [datasets[0].get(i) for i in range(n1)] + \\\n",
    "                [datasets[1].get(i) for i in range(n2)] + \\\n",
    "                [datasets[2].get(i) for i in range(n3)]\n",
    "\n",
    "    datasets[0]._indices = None\n",
    "    datasets[0]._data_list = data_list\n",
    "    datasets[0].data, datasets[0].slices = datasets[0].collate(data_list)\n",
    "    split_idxs = [list(range(n1)),\n",
    "                  list(range(n1, n1 + n2)),\n",
    "                  list(range(n1 + n2, n1 + n2 + n3))]\n",
    "    datasets[0].split_idxs = split_idxs\n",
    "\n",
    "    return datasets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bbcf153-c348-4b3e-bbcd-944e70d0b012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(voc_dataset):\n",
    "    total_nodes, total_edges, avg_nodes, avg_edges = 0,0,0,0\n",
    "    all_node_degs = torch.empty(0)\n",
    "    all_avg_shortest_paths, all_diameters = [], []\n",
    "    for g in tqdm(voc_dataset):\n",
    "        total_nodes += g.num_nodes\n",
    "        total_edges += g.num_edges\n",
    "        idx = g.edge_index[1]\n",
    "        deg = torch_geometric.utils.degree(idx, g.num_nodes, dtype=torch.long)\n",
    "        all_node_degs = torch.cat((all_node_degs, deg))\n",
    "        g_nx = torch_geometric.utils.to_networkx(g)\n",
    "        \n",
    "        \n",
    "        # !!! NOTE\n",
    "        # For shortest path and diameter computations, we convert the digraph to undirected\n",
    "        g_nx = g_nx.to_undirected()\n",
    "        all_avg_shortest_paths.append(nx.average_shortest_path_length(g_nx))\n",
    "        all_diameters.append(nx.diameter(g_nx))\n",
    "        \n",
    "    print(\"total graphs: \", len(voc_dataset))\n",
    "    print(\"total nodes: \", total_nodes)\n",
    "    print(\"total edges: \", total_edges)\n",
    "    print(\"avg_nodes: \", total_nodes/len(voc_dataset)*1.0)\n",
    "    print(\"avg_edges: \", total_edges/len(voc_dataset)*1.0)\n",
    "    print(\"mean node deg: \", torch.mean(all_node_degs))\n",
    "    print(\"avg. of avg. shortest paths: \", np.mean(all_avg_shortest_paths))\n",
    "    print(\"std. of avg. shortest paths: \", np.std(all_avg_shortest_paths))\n",
    "    print(\"avg. diameter: \", np.mean(all_diameters))\n",
    "    print(\"std. diameter: \", np.std(all_diameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb5a677-bbbe-4a73-abc9-228d7a1160fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_dataset = join_dataset_splits(\n",
    "        [VOCSuperpixels(root='../../datasets/VOCSuperpixels', name='edge_wt_region_boundary',\n",
    "                        slic_compactness=10,\n",
    "                        split=split)\n",
    "         for split in ['train', 'val', 'test']]\n",
    "    )\n",
    "get_stats(voc_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e932f6e3-2662-45b6-bd4d-7c71dc09d2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_dataset = join_dataset_splits(\n",
    "        [COCOSuperpixels(root='../../datasets/COCOSuperpixels', name='edge_wt_only_coord',\n",
    "                        slic_compactness=10,\n",
    "                        split=split)\n",
    "         for split in ['train', 'val', 'test']]\n",
    "    )\n",
    "#get_stats(coco_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2d76ff1-1199-43da-a85a-f7e246b617de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 55/15535 [00:01<08:01, 32.16it/s]\n"
     ]
    },
    {
     "ename": "NetworkXError",
     "evalue": "Graph is not connected.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNetworkXError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m pep_func_dataset \u001b[39m=\u001b[39m PeptidesFunctionalDataset(root\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m../../datasets/peptides-functional\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m get_stats(pep_func_dataset)\n",
      "Cell \u001b[0;32mIn[5], line 17\u001b[0m, in \u001b[0;36mget_stats\u001b[0;34m(voc_dataset)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[39m# !!! NOTE\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     \u001b[39m# For shortest path and diameter computations, we convert the digraph to undirected\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     g_nx \u001b[39m=\u001b[39m g_nx\u001b[39m.\u001b[39mto_undirected()\n\u001b[0;32m---> 17\u001b[0m     all_avg_shortest_paths\u001b[39m.\u001b[39mappend(nx\u001b[39m.\u001b[39;49maverage_shortest_path_length(g_nx))\n\u001b[1;32m     18\u001b[0m     all_diameters\u001b[39m.\u001b[39mappend(nx\u001b[39m.\u001b[39mdiameter(g_nx))\n\u001b[1;32m     20\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mtotal graphs: \u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mlen\u001b[39m(voc_dataset))\n",
      "File \u001b[0;32m~/.conda/envs/lrgb/lib/python3.9/site-packages/networkx/algorithms/shortest_paths/generic.py:416\u001b[0m, in \u001b[0;36maverage_shortest_path_length\u001b[0;34m(G, weight, method)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[39m# Shortest path length is undefined if the graph is not connected.\u001b[39;00m\n\u001b[1;32m    415\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m G\u001b[39m.\u001b[39mis_directed() \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m nx\u001b[39m.\u001b[39mis_connected(G):\n\u001b[0;32m--> 416\u001b[0m     \u001b[39mraise\u001b[39;00m nx\u001b[39m.\u001b[39mNetworkXError(\u001b[39m\"\u001b[39m\u001b[39mGraph is not connected.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    418\u001b[0m \u001b[39m# Compute all-pairs shortest paths.\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpath_length\u001b[39m(v):\n",
      "\u001b[0;31mNetworkXError\u001b[0m: Graph is not connected."
     ]
    }
   ],
   "source": [
    "pep_func_dataset = PeptidesFunctionalDataset(root='../../datasets/peptides-functional')\n",
    "get_stats(pep_func_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "afa9d3b7-cb6f-4ace-aeb6-b444d20acab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {'edge_index': tensor([      0,     244,     926,  ..., 4773604, 4773842, 4773974]),\n",
       "             'edge_attr': tensor([      0,     244,     926,  ..., 4773604, 4773842, 4773974]),\n",
       "             'x': tensor([      0,     119,     457,  ..., 2344679, 2344792, 2344859]),\n",
       "             'y': tensor([    0,     1,     2,  ..., 15533, 15534, 15535]),\n",
       "             'train_mask': tensor([    0, 15535]),\n",
       "             'val_mask': tensor([    0, 15535]),\n",
       "             'test_mask': tensor([    0, 15535])})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataset_dir = \"../../datasets/peptides-functional\"\n",
    "name = \"peptides_functional\"\n",
    "\n",
    "dataset = PeptidesFunctionalDataset(dataset_dir)\n",
    "\n",
    "s_dict = dataset.get_idx_split()\n",
    "dataset.split_idxs = [s_dict[s] for s in ['train', 'val', 'test']]\n",
    "\n",
    "dataset\n",
    "\n",
    "if hasattr(dataset, 'split_idxs'):\n",
    "  set_dataset_splits(dataset, dataset.split_idxs)\n",
    "  delattr(dataset, 'split_idxs')\n",
    "\n",
    "prepare_splits(dataset)\n",
    "\n",
    "vars(dataset)\n",
    "\n",
    "# print(\"FLAG\")\n",
    "datasetDict = dataset.slices\n",
    "datasetDict\n",
    "\n",
    "# print(datasetDict['x'].shape)\n",
    "# print(datasetDict['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01a51e93",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "libtiff.so.5: cannot open shared object file: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/lrgb/lib/python3.9/site-packages/matplotlib/__init__.py:131\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpackaging\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mversion\u001b[39;00m \u001b[39mimport\u001b[39;00m parse \u001b[39mas\u001b[39;00m parse_version\n\u001b[1;32m    129\u001b[0m \u001b[39m# cbook must import matplotlib only within function\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[39m# definitions, so it is safe to import from it here.\u001b[39;00m\n\u001b[0;32m--> 131\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m _api, _version, cbook, _docstring, rcsetup\n\u001b[1;32m    132\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcbook\u001b[39;00m \u001b[39mimport\u001b[39;00m sanitize_sequence\n\u001b[1;32m    133\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_api\u001b[39;00m \u001b[39mimport\u001b[39;00m MatplotlibDeprecationWarning\n",
      "File \u001b[0;32m~/.conda/envs/lrgb/lib/python3.9/site-packages/matplotlib/rcsetup.py:27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m \u001b[39mimport\u001b[39;00m _api, cbook\n\u001b[1;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcbook\u001b[39;00m \u001b[39mimport\u001b[39;00m ls_mapper\n\u001b[0;32m---> 27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcolors\u001b[39;00m \u001b[39mimport\u001b[39;00m Colormap, is_color_like\n\u001b[1;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_fontconfig_pattern\u001b[39;00m \u001b[39mimport\u001b[39;00m parse_fontconfig_pattern\n\u001b[1;32m     29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_enums\u001b[39;00m \u001b[39mimport\u001b[39;00m JoinStyle, CapStyle\n",
      "File \u001b[0;32m~/.conda/envs/lrgb/lib/python3.9/site-packages/matplotlib/colors.py:51\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnumbers\u001b[39;00m \u001b[39mimport\u001b[39;00m Number\n\u001b[1;32m     50\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mre\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mPIL\u001b[39;00m \u001b[39mimport\u001b[39;00m Image\n\u001b[1;32m     52\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mPIL\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mPngImagePlugin\u001b[39;00m \u001b[39mimport\u001b[39;00m PngInfo\n\u001b[1;32m     54\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmpl\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/lrgb/lib/python3.9/site-packages/PIL/Image.py:100\u001b[0m\n\u001b[1;32m     91\u001b[0m MAX_IMAGE_PIXELS \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(\u001b[39m1024\u001b[39m \u001b[39m*\u001b[39m \u001b[39m1024\u001b[39m \u001b[39m*\u001b[39m \u001b[39m1024\u001b[39m \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m4\u001b[39m \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m3\u001b[39m)\n\u001b[1;32m     94\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     95\u001b[0m     \u001b[39m# If the _imaging C module is not present, Pillow will not load.\u001b[39;00m\n\u001b[1;32m     96\u001b[0m     \u001b[39m# Note that other modules should not refer to _imaging directly;\u001b[39;00m\n\u001b[1;32m     97\u001b[0m     \u001b[39m# import Image and use the Image.core variable instead.\u001b[39;00m\n\u001b[1;32m     98\u001b[0m     \u001b[39m# Also note that Image.core is not a publicly documented interface,\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[39m# and should be considered private and subject to change.\u001b[39;00m\n\u001b[0;32m--> 100\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m _imaging \u001b[39mas\u001b[39;00m core\n\u001b[1;32m    102\u001b[0m     \u001b[39mif\u001b[39;00m __version__ \u001b[39m!=\u001b[39m \u001b[39mgetattr\u001b[39m(core, \u001b[39m\"\u001b[39m\u001b[39mPILLOW_VERSION\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    103\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[1;32m    104\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThe _imaging extension was built for another version of Pillow or PIL:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    105\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCore version: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mgetattr\u001b[39m(core,\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39mPILLOW_VERSION\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m \u001b[39m\u001b[39mNone\u001b[39;00m)\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    106\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPillow version: \u001b[39m\u001b[39m{\u001b[39;00m__version__\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    107\u001b[0m         )\n",
      "\u001b[0;31mImportError\u001b[0m: libtiff.so.5: cannot open shared object file: No such file or directory"
     ]
    }
   ],
   "source": [
    "import matplotlib"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
